name: IP Scraper

on:
  schedule:
    - cron: '0 0 * * *'  # 每天 UTC 时间 00:00 运行
  workflow_dispatch:      # 允许手动触发

jobs:
  scrape:
    runs-on: ubuntu-latest
    permissions:
      contents: write     # 关键权限：允许推送代码

    steps:
      # 1. 检出代码
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0  # 获取完整提交历史

      # 2. 设置 Python 环境
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.9'

      # 3. 安装系统依赖和 Python 包
      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y wget
          pip install selenium webdriver-manager beautifulsoup4 geoip2 requests

      # 4. 运行爬虫脚本
      - name: Run scraper
        id: scrape  # 注意：id 应该与 step 同级，不是 env 的子项
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          python scrape_ips.py || [ $(wc -l < ip.txt || echo 0) -ge 10 ]
          echo "IP_COUNT=$(wc -l < ip.txt | xargs)" >> $GITHUB_OUTPUT

      # 5. 条件推送（仅当 IP≥10 时）
      - name: Commit and push changes
        if: ${{ steps.scrape.outputs.IP_COUNT >= 10 }}
        run: |
          git config --global user.name "GitHub Actions Bot"
          git config --global user.email "actions@github.com"
          git add ip.txt
          git commit -m "Auto-update IP list (${{ steps.scrape.outputs.IP_COUNT }} IPs)"
          git push
