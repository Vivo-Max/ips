name: Scrape and Update IPs
on:
  schedule:
    - cron: '0 */6 * * *'  # 每6小时运行一次（可选定时任务）
  workflow_dispatch:       # 允许手动触发
  push:
    branches:
      - main              # 仅在 main 分支推送时忽略（避免循环触发）

jobs:
  scrape-and-push:
    runs-on: ubuntu-latest
    permissions:
      contents: write     # 关键：允许工作流推送更改

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # 获取完整 Git 历史（避免推送冲突）

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Install dependencies
        run: |
          pip install selenium beautifulsoup4 geoip2

      - name: Run scraper
        id: scrape
        run: |
          # 运行脚本，如果失败则检查 IP 数量是否≥10
          python scrape_ips.py || [ $(wc -l < ip.txt || echo 0) -ge 10 ]
          echo "IP_COUNT=$(wc -l < ip.txt | xargs)" >> $GITHUB_OUTPUT

      - name: Commit and push changes
        if: ${{ steps.scrape.outputs.IP_COUNT >= 10 }}  # 仅当 IP≥10 时推送
        run: |
          git config --global user.name "GitHub Actions Bot"
          git config --global user.email "actions@github.com"
          git add ip.txt
          git commit -m "Auto-update IP list (${{ steps.scrape.outputs.IP_COUNT }} IPs)"
          git push
