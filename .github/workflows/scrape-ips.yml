name: IP Scraper

on:
  schedule:
    - cron: '0 0 * * *'
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.9'

    - name: Install dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y wget
        pip install selenium webdriver-manager beautifulsoup4 geoip2 requests

    - name: Run scraper
      run: |
        python scrape_ips.py || [ $(wc -l < ip.txt || echo 0) -ge 10 ]  # 至少10个IP才算成功
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        id: scrape
        run: |
          # 运行脚本，如果失败则检查 IP 数量是否≥10
          python scrape_ips.py || [ $(wc -l < ip.txt || echo 0) -ge 10 ]
          echo "IP_COUNT=$(wc -l < ip.txt | xargs)" >> $GITHUB_OUTPUT

      - name: Commit and push changes
        if: ${{ steps.scrape.outputs.IP_COUNT >= 10 }}  # 仅当 IP≥10 时推送
        run: |
          git config --global user.name "GitHub Actions Bot"
          git config --global user.email "actions@github.com"
          git add ip.txt
          git commit -m "Auto-update IP list (${{ steps.scrape.outputs.IP_COUNT }} IPs)"
          git push
